{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec91ad5",
   "metadata": {},
   "source": [
    "\n",
    "# Comprehensive Animal Classification Model Notebook\n",
    "\n",
    "This notebook provides a detailed guide through the process of developing a machine learning model capable of classifying images of animals from the North East United States into two categories: domestic and predator. The model utilizes TensorFlow, Keras, and a pre-trained InceptionV3 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7399c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import albumentations as Alb\n",
    "import joblib\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d85337",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Code for data preparation including loading, preprocessing, and augmentations\n",
    "path = \"path_to_images/\"\n",
    "labels = [\"domestic\", \"predator\"]\n",
    "images = []\n",
    "labelImageMap = {}\n",
    "\n",
    "for label in labels:\n",
    "    for image_file in os.listdir(os.path.join(path, label)):\n",
    "        image_path = os.path.join(path, label, image_file)\n",
    "        images.append(image_path)\n",
    "        labelImageMap[image_path] = label\n",
    "\n",
    "df = pd.DataFrame(list(labelImageMap.items()), columns=['ImagePath', 'Label'])\n",
    "encoder = LabelEncoder()\n",
    "df['EncodedLabel'] = encoder.fit_transform(df['Label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5ee3a0",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb525514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Code for model creation, including the base model and additional layers\n",
    "base_model = InceptionV3(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Adding custom layers\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359721e4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b811638",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Code for training the model with early stopping and learning rate reduction\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(monitor='val_loss', patience=3)]\n",
    "history = model.fit(train_data, validation_data=val_data, epochs=20, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e44e0c",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6669069",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utility functions for image preprocessing and prediction\n",
    "def preprocess_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [224, 224])\n",
    "    img /= 255.0\n",
    "    return img\n",
    "\n",
    "def predict_image(model, image_path):\n",
    "    img = preprocess_image(image_path)\n",
    "    img = np.expand_dims(img, axis=0)  # Make it a batch of one\n",
    "    predictions = model.predict(img)\n",
    "    return predictions[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbecdc30",
   "metadata": {},
   "source": [
    "## Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation and visualization of the model's performance\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
